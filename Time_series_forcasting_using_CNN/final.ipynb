{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIme series forcasting using CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ml-nest/passion_projects/blob/main/Time_series_forcasting_using_CNN/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghnrjr-2Ir9n"
      },
      "source": [
        "# This notebook prsents how to create a timeseries forcasting model using CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xni_etkQ8eUu"
      },
      "source": [
        "def create_dataset(X, y, time_steps_x, time_steps_y):\n",
        "    \"\"\"\n",
        "    Creating windowed dataset for feeding into the neural network\n",
        "\n",
        "    Arguments :\n",
        "\n",
        "    df : dataframe which has to be converted to 3D array from 2D array\n",
        "    window_size : timeperiod during which the model must be trained on a rolling basis\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    np.array(arr) : an array of arrays where every array is a window (3D array)\n",
        "\n",
        "    \"\"\"\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps_x - time_steps_y +1):\n",
        "        Xs.append(X.iloc[i:(i + time_steps_x)].values)\n",
        "        \n",
        "    for i in range(time_steps_x, len(X) - time_steps_y + 1):\n",
        "        ys.append(y.iloc[i:i + time_steps_y].values)\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsmteDJqJCZU"
      },
      "source": [
        "- Univariate CNN Models\n",
        "- Multivariate CNN Models\n",
        "- Multi-Step CNN Models\n",
        "- Multivariate Multi-Step CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTpiP_IxD0Ie"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diDbI2WQFJzB"
      },
      "source": [
        "# Creating a dummy dataframe\n",
        "df = pd.DataFrame({'A':[10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
        "                   'B':[15, 25, 35, 45, 55, 65, 75, 85, 95]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrzHBvEr8eUw"
      },
      "source": [
        "# Univariate CNN Models\n",
        "Univariate time series are datasets comprised of a single series of observations with a temporal ordering and a model is required to learn from the series of past observations to predict the next value in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSyaIMSg8eUy",
        "outputId": "782ff96e-cd3b-4d5e-b21f-2898afe4865d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# choose a number of time steps\n",
        "x_steps = 3\n",
        "y_steps = 1\n",
        "n_features = 1\n",
        "\n",
        "# split into samples\n",
        "X, y = create_dataset(df[['A']], df[['A']], x_steps, y_steps)\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(x_steps, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([100, 110, 120])\n",
        "x_input = x_input.reshape((1, x_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[137.17075]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrAPQVn1IYpW"
      },
      "source": [
        "# Multivariate CNN Models\n",
        "There is more than one observation in one timestep\n",
        "There are of 2 main types:\n",
        "- Multiple Input Series\n",
        "- Multiple Parallel Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-s7Qdb8I_M5",
        "outputId": "fcfc5e91-a3db-48b5-91a1-85cf546154de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### Multiple Input Series"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%markdown` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzRjanAO8eUz"
      },
      "source": [
        "# multivariate cnn example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        " \n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=1000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y-qiyld8eU0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD7B2Tg48eU0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuqIfdgD8eU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJqa5SVA8eU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPotOJXK8eU1"
      },
      "source": [
        "# multivariate multi-headed 1d cnn example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        " \n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# one time series per head\n",
        "n_features = 1\n",
        "# separate input data\n",
        "X1 = X[:, :, 0].reshape(X.shape[0], X.shape[1], n_features)\n",
        "X2 = X[:, :, 1].reshape(X.shape[0], X.shape[1], n_features)\n",
        "# first input model\n",
        "visible1 = Input(shape=(n_steps, n_features))\n",
        "cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
        "cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
        "cnn1 = Flatten()(cnn1)\n",
        "# second input model\n",
        "visible2 = Input(shape=(n_steps, n_features))\n",
        "cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible2)\n",
        "cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
        "cnn2 = Flatten()(cnn2)\n",
        "# merge input models\n",
        "merge = concatenate([cnn1, cnn2])\n",
        "dense = Dense(50, activation='relu')(merge)\n",
        "output = Dense(1)(dense)\n",
        "model = Model(inputs=[visible1, visible2], outputs=output)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit([X1, X2], y, epochs=1000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x1 = x_input[:, 0].reshape((1, n_steps, n_features))\n",
        "x2 = x_input[:, 1].reshape((1, n_steps, n_features))\n",
        "yhat = model.predict([x1, x2], verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cQ-tSIi8eU2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaPHkFEc8eU3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m9i7bf48eU3"
      },
      "source": [
        "## Multiple Parallel Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15CL_W98eU4"
      },
      "source": [
        "# multivariate output 1d cnn example\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        " \n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "# the dataset knows the number of features, e.g. 2\n",
        "n_features = X.shape[2]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(n_features))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=3000, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLDE2rVD8eU5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UAtd07R8eU5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxjO9xsg8eU5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}