{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "analysis.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrQwTakk8CfB"
      },
      "source": [
        "# Reading the dataset\n",
        "import pandas as pd\n",
        "from math import exp\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/wheat-seeds.csv\", header = None)"
      ],
      "id": "UrQwTakk8CfB",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1buEyYGLggKk",
        "outputId": "f127d383-6776-4d72-cd0c-cdc8dba40454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "id": "1buEyYGLggKk",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.26</td>\n",
              "      <td>14.84</td>\n",
              "      <td>0.8710</td>\n",
              "      <td>5.763</td>\n",
              "      <td>3.312</td>\n",
              "      <td>2.221</td>\n",
              "      <td>5.220</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.88</td>\n",
              "      <td>14.57</td>\n",
              "      <td>0.8811</td>\n",
              "      <td>5.554</td>\n",
              "      <td>3.333</td>\n",
              "      <td>1.018</td>\n",
              "      <td>4.956</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14.29</td>\n",
              "      <td>14.09</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>5.291</td>\n",
              "      <td>3.337</td>\n",
              "      <td>2.699</td>\n",
              "      <td>4.825</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.84</td>\n",
              "      <td>13.94</td>\n",
              "      <td>0.8955</td>\n",
              "      <td>5.324</td>\n",
              "      <td>3.379</td>\n",
              "      <td>2.259</td>\n",
              "      <td>4.805</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16.14</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>5.658</td>\n",
              "      <td>3.562</td>\n",
              "      <td>1.355</td>\n",
              "      <td>5.175</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1       2      3      4      5      6  7\n",
              "0  15.26  14.84  0.8710  5.763  3.312  2.221  5.220  1\n",
              "1  14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
              "2  14.29  14.09  0.9050  5.291  3.337  2.699  4.825  1\n",
              "3  13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
              "4  16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pViRH88_PaG"
      },
      "source": [
        "# Initialize Network\n",
        "\n",
        "A network is organized into layers. The input layer is really just a row from our training dataset. The first real layer is the hidden layer. This is followed by the output layer that has one neuron for each class value.\n",
        "\n",
        "So initializing weights for each beta coefficient i.e. numberof inputs+1 in each neuron of the hidden layer. Now this output of hidden layer will be sent to the output layer which will have n number of neurons where n is the number of classes in the dataset. Each output neuron will have 2 coefficients one for the ouput from the hidden layer and other as the intercept.\n",
        "\n",
        "Basically weights to be initialized for the current neuron are neurons in the previous layer + 1"
      ],
      "id": "9pViRH88_PaG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9cq4hsqm7Mx"
      },
      "source": [
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network"
      ],
      "id": "N9cq4hsqm7Mx",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGwtBcnAhAtU",
        "outputId": "ecd348f4-171c-4f75-b741-0ff4429effc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed(1)\n",
        "network = initialize_network(2, 2, 2)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "id": "TGwtBcnAhAtU",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}]\n",
            "[{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmL_Rpq_sAlO"
      },
      "source": [
        "# Forward Propogation\n",
        "We can calculate an output from a neural network by propagating an input signal through each layer until the output layer outputs its values.\n",
        "It has 3 parts to it:-\n",
        "1. Neuron Activation\n",
        "2. Neuron Transfer\n",
        "3. Forward Propagation\n",
        "\n",
        "Storeplanning NN logic"
      ],
      "id": "BmL_Rpq_sAlO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_XTsSeuvRd"
      },
      "source": [
        "## Neuron Activation\n",
        "It is the z value of the neuron or the weighted sum of outputs from all the neurons in the previous layers"
      ],
      "id": "N9_XTsSeuvRd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCn5VgJMyYOn"
      },
      "source": [
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation"
      ],
      "id": "fCn5VgJMyYOn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7_ODfY_xDZZ"
      },
      "source": [
        "## Neuron Transfer\n",
        "We need to transfer this activation through a non linear function to see what the output actually is. We use a transfer function for this, in this case we use sigmoid function."
      ],
      "id": "b7_ODfY_xDZZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87JCXQk0ybE6"
      },
      "source": [
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))"
      ],
      "id": "87JCXQk0ybE6",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrntZuRay_3E"
      },
      "source": [
        "## Forward Propagation\n",
        "We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer."
      ],
      "id": "TrntZuRay_3E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zmSpiXhzXbt"
      },
      "source": [
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs"
      ],
      "id": "2zmSpiXhzXbt",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fxVPVOBzYeh",
        "outputId": "44a8aeef-a8ac-46c7-f2ea-5dd3b78c7717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testing out the forward propogation\n",
        "network = [[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
        "\t\t[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "row = [1, 0]\n",
        "output = forward_propagate(network, row)\n",
        "print(output)"
      ],
      "id": "_fxVPVOBzYeh",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6629970129852887, 0.7253160725279748]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFmYRmMN0pJv"
      },
      "source": [
        "# Back Propagate Error"
      ],
      "id": "xFmYRmMN0pJv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Seyj5BbmhPP9",
        "outputId": "4812784f-1ed1-4351-adbb-1531c6472cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        " \n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        " \n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        " \n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        " \n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        " \n",
        "# Test training backprop algorithm\n",
        "seed(1)\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "\t[1.465489372,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "id": "Seyj5BbmhPP9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">epoch=0, lrate=0.500, error=6.350\n",
            ">epoch=1, lrate=0.500, error=5.531\n",
            ">epoch=2, lrate=0.500, error=5.221\n",
            ">epoch=3, lrate=0.500, error=4.951\n",
            ">epoch=4, lrate=0.500, error=4.519\n",
            ">epoch=5, lrate=0.500, error=4.173\n",
            ">epoch=6, lrate=0.500, error=3.835\n",
            ">epoch=7, lrate=0.500, error=3.506\n",
            ">epoch=8, lrate=0.500, error=3.192\n",
            ">epoch=9, lrate=0.500, error=2.898\n",
            ">epoch=10, lrate=0.500, error=2.626\n",
            ">epoch=11, lrate=0.500, error=2.377\n",
            ">epoch=12, lrate=0.500, error=2.153\n",
            ">epoch=13, lrate=0.500, error=1.953\n",
            ">epoch=14, lrate=0.500, error=1.774\n",
            ">epoch=15, lrate=0.500, error=1.614\n",
            ">epoch=16, lrate=0.500, error=1.472\n",
            ">epoch=17, lrate=0.500, error=1.346\n",
            ">epoch=18, lrate=0.500, error=1.233\n",
            ">epoch=19, lrate=0.500, error=1.132\n",
            "[{'weights': [-1.4688375095432327, 1.850887325439514, 1.0858178629550297], 'output': 0.029980305604426185, 'delta': -0.0059546604162323625}, {'weights': [0.37711098142462157, -0.0625909894552989, 0.2765123702642716], 'output': 0.9456229000211323, 'delta': 0.0026279652850863837}]\n",
            "[{'weights': [2.515394649397849, -0.3391927502445985, -0.9671565426390275], 'output': 0.23648794202357587, 'delta': -0.04270059278364587}, {'weights': [-2.5584149848484263, 1.0036422106209202, 0.42383086467582715], 'output': 0.7790535202438367, 'delta': 0.03803132596437354}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}